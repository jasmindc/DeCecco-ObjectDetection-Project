{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jasmindc/great-barrier-reef-object-detection?scriptVersionId=145349838\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Great Barrier Reef Object Detection","metadata":{}},{"cell_type":"markdown","source":"## Initial Settings","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport ast\nimport os\nimport cv2\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib.transforms import Bbox\n\npd.set_option(\"display.max_colwidth\",None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T16:03:12.936852Z","iopub.execute_input":"2023-10-01T16:03:12.937181Z","iopub.status.idle":"2023-10-01T16:03:12.943477Z","shell.execute_reply.started":"2023-10-01T16:03:12.937159Z","shell.execute_reply":"2023-10-01T16:03:12.942325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tensorflow-great-barrier-reef/train.csv')\ntest = pd.read_csv('/kaggle/input/tensorflow-great-barrier-reef/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tensorflow-great-barrier-reef/example_sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:12.944701Z","iopub.execute_input":"2023-10-01T16:03:12.945382Z","iopub.status.idle":"2023-10-01T16:03:12.990079Z","shell.execute_reply.started":"2023-10-01T16:03:12.945359Z","shell.execute_reply":"2023-10-01T16:03:12.989386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Dataset","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:12.991741Z","iopub.execute_input":"2023-10-01T16:03:12.991985Z","iopub.status.idle":"2023-10-01T16:03:13.000972Z","shell.execute_reply.started":"2023-10-01T16:03:12.991964Z","shell.execute_reply":"2023-10-01T16:03:13.0002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:13.002258Z","iopub.execute_input":"2023-10-01T16:03:13.002888Z","iopub.status.idle":"2023-10-01T16:03:13.015441Z","shell.execute_reply.started":"2023-10-01T16:03:13.002853Z","shell.execute_reply":"2023-10-01T16:03:13.014862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train dataset Info:\")\nprint(train.info())\nprint(\"\\n\")\nprint(\"test dataset Info:\")\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:13.017071Z","iopub.execute_input":"2023-10-01T16:03:13.017666Z","iopub.status.idle":"2023-10-01T16:03:13.042317Z","shell.execute_reply.started":"2023-10-01T16:03:13.017644Z","shell.execute_reply":"2023-10-01T16:03:13.041362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boxplot (to find Outliers)\nplt.figure(figsize=(15,15))\npos = 1\nfor i in train.columns:\n        if(type(train[i][0]) != str):\n                plt.subplot(4, 3, pos)\n                sns.boxplot(train[i])\n                pos += 1","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:13.04327Z","iopub.execute_input":"2023-10-01T16:03:13.044064Z","iopub.status.idle":"2023-10-01T16:03:13.573187Z","shell.execute_reply.started":"2023-10-01T16:03:13.044041Z","shell.execute_reply":"2023-10-01T16:03:13.57221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation Matrix ( help to choose columns to drop: the most correlated!)\ncorrelation_matrix = train.corr()\nsns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:13.574854Z","iopub.execute_input":"2023-10-01T16:03:13.575212Z","iopub.status.idle":"2023-10-01T16:03:13.900684Z","shell.execute_reply.started":"2023-10-01T16:03:13.57518Z","shell.execute_reply":"2023-10-01T16:03:13.899884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### No noticeable positive or negative correlation detected","metadata":{}},{"cell_type":"code","source":"#check if there are null val\nplt.figure(figsize=(10,10))\nsns.heatmap(train.isna())","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:13.901974Z","iopub.execute_input":"2023-10-01T16:03:13.902228Z","iopub.status.idle":"2023-10-01T16:03:14.774469Z","shell.execute_reply.started":"2023-10-01T16:03:13.902207Z","shell.execute_reply":"2023-10-01T16:03:14.773501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see from the plot here are no nulls detected","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:14.77576Z","iopub.execute_input":"2023-10-01T16:03:14.776443Z","iopub.status.idle":"2023-10-01T16:03:14.783267Z","shell.execute_reply.started":"2023-10-01T16:03:14.77639Z","shell.execute_reply":"2023-10-01T16:03:14.782354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of video_frame per video\ntrain.groupby(\"video_id\")[\"video_frame\"].count()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:14.784617Z","iopub.execute_input":"2023-10-01T16:03:14.784939Z","iopub.status.idle":"2023-10-01T16:03:14.797634Z","shell.execute_reply.started":"2023-10-01T16:03:14.784916Z","shell.execute_reply":"2023-10-01T16:03:14.796881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot video_id distribution ( number of images per video)\nplt.figure(figsize=(10,10))\nsns.histplot(data=train, x=\"video_id\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:14.800574Z","iopub.execute_input":"2023-10-01T16:03:14.801139Z","iopub.status.idle":"2023-10-01T16:03:15.139597Z","shell.execute_reply.started":"2023-10-01T16:03:14.801115Z","shell.execute_reply":"2023-10-01T16:03:15.138865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding image path from train_images folder to the dataset images (train folder)\ntrain[\"image_path\"] = '/kaggle/input/tensorflow-great-barrier-reef/train_images/video_'+train[\"video_id\"].astype(str)+'/'+train[\"image_id\"].apply(lambda x: x.split(\"-\")[1])+\".jpg\"","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:15.14099Z","iopub.execute_input":"2023-10-01T16:03:15.141282Z","iopub.status.idle":"2023-10-01T16:03:15.174592Z","shell.execute_reply.started":"2023-10-01T16:03:15.141257Z","shell.execute_reply":"2023-10-01T16:03:15.173507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:15.175968Z","iopub.execute_input":"2023-10-01T16:03:15.176264Z","iopub.status.idle":"2023-10-01T16:03:15.186454Z","shell.execute_reply.started":"2023-10-01T16:03:15.176239Z","shell.execute_reply":"2023-10-01T16:03:15.185403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting random images to check previous step\n\nrows, cols = 2, 2\nfig, axs = plt.subplots(rows, cols, figsize=(15,10))\nfor i,ax in zip(train, axs.ravel()):\n    random_image = random.randint(0,len(train)-1)\n    img = mpimg.imread(train[\"image_path\"][random_image])\n    ax.imshow(img)\n    ax.set_title(f'Image ID: {train[\"image_id\"][random_image]}',{\"fontsize\": 20})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:15.187682Z","iopub.execute_input":"2023-10-01T16:03:15.188022Z","iopub.status.idle":"2023-10-01T16:03:17.083151Z","shell.execute_reply.started":"2023-10-01T16:03:15.187999Z","shell.execute_reply":"2023-10-01T16:03:17.082477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Annotations\n\n-  Annotations have the following format: [{'x': 645, 'y': 182, 'width': 41, 'height': 45}]\n-  There can be multiple records in one list\n\n","metadata":{}},{"cell_type":"code","source":"len(train[\"annotations\"])  ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.084235Z","iopub.execute_input":"2023-10-01T16:03:17.085062Z","iopub.status.idle":"2023-10-01T16:03:17.090168Z","shell.execute_reply.started":"2023-10-01T16:03:17.085036Z","shell.execute_reply":"2023-10-01T16:03:17.089279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"annotations\"].dtype","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.091215Z","iopub.execute_input":"2023-10-01T16:03:17.09167Z","iopub.status.idle":"2023-10-01T16:03:17.103687Z","shell.execute_reply.started":"2023-10-01T16:03:17.091646Z","shell.execute_reply":"2023-10-01T16:03:17.102735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.annotations.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.105062Z","iopub.execute_input":"2023-10-01T16:03:17.105702Z","iopub.status.idle":"2023-10-01T16:03:17.129001Z","shell.execute_reply.started":"2023-10-01T16:03:17.105649Z","shell.execute_reply":"2023-10-01T16:03:17.127393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.annotations.unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.130171Z","iopub.execute_input":"2023-10-01T16:03:17.130851Z","iopub.status.idle":"2023-10-01T16:03:17.139006Z","shell.execute_reply.started":"2023-10-01T16:03:17.130824Z","shell.execute_reply":"2023-10-01T16:03:17.138172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculate records with and without annotations\nrecords_with_annotations = train[train[\"annotations\"] != \"[]\"]\nnum_records_with_annotations = records_with_annotations[\"annotations\"].count()\n\nrecords_without_annotations = train[train[\"annotations\"] == \"[]\"]\nnum_records_without_annotations = records_without_annotations[\"annotations\"].count()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.14007Z","iopub.execute_input":"2023-10-01T16:03:17.14081Z","iopub.status.idle":"2023-10-01T16:03:17.156465Z","shell.execute_reply.started":"2023-10-01T16:03:17.140784Z","shell.execute_reply":"2023-10-01T16:03:17.155477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot records annotation distribution\nsns.barplot(x = [\"record with annotations\", \"record without annotations\"], y = [num_records_with_annotations, num_records_without_annotations], palette = \"colorblind\")\nplt.title(\"Records Annotation Distribution\", fontsize = 30)\nplt.xlabel(\"Annotation\", fontsize = 15)\nplt.ylabel(\"Count\", fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.157956Z","iopub.execute_input":"2023-10-01T16:03:17.158225Z","iopub.status.idle":"2023-10-01T16:03:17.462765Z","shell.execute_reply.started":"2023-10-01T16:03:17.158202Z","shell.execute_reply":"2023-10-01T16:03:17.461439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Records with annotations\nrecords_with_annotations","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.464766Z","iopub.execute_input":"2023-10-01T16:03:17.465561Z","iopub.status.idle":"2023-10-01T16:03:17.488547Z","shell.execute_reply.started":"2023-10-01T16:03:17.465499Z","shell.execute_reply":"2023-10-01T16:03:17.487382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of records without annotations\nprint(\"There are \"+ str(num_records_without_annotations)+ \" records without annotations and \"+ str(num_records_with_annotations)+ \" records with annotations.\")\n            ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.489867Z","iopub.execute_input":"2023-10-01T16:03:17.490219Z","iopub.status.idle":"2023-10-01T16:03:17.493929Z","shell.execute_reply.started":"2023-10-01T16:03:17.490198Z","shell.execute_reply":"2023-10-01T16:03:17.493326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the number of total annotations within the frame and adding to the data\ntrain[\"no_annotations\"] = train[\"annotations\"].apply(lambda x: len(eval(x)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:17.494884Z","iopub.execute_input":"2023-10-01T16:03:17.495121Z","iopub.status.idle":"2023-10-01T16:03:17.765736Z","shell.execute_reply.started":"2023-10-01T16:03:17.495101Z","shell.execute_reply":"2023-10-01T16:03:17.764807Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total number of annotations\ntot=0\nfor i in train[\"video_frame\"]:\n    if train[\"no_annotations\"][i] != 0:\n        tot = tot+train[\"no_annotations\"][i]\n\nprint(\"There are \" + str(tot)+ \" annotations in total\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:07:04.199905Z","iopub.execute_input":"2023-10-01T16:07:04.200281Z","iopub.status.idle":"2023-10-01T16:07:04.364111Z","shell.execute_reply.started":"2023-10-01T16:07:04.200257Z","shell.execute_reply":"2023-10-01T16:07:04.363355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are a lot of records without annotations, this can make it difficult creating a good model. But, previous information are useful to check upon the model training part.","metadata":{}},{"cell_type":"code","source":"#Plot annotation length distribution for records that do have annotations\n\nsns.countplot(x=records_with_annotations[\"annotations\"].apply(lambda x: len(x)).value_counts(),palette = \"colorblind\")\nplt.title(\"Annotation Length Distribution\", fontsize = 30)\nplt.xlabel(\"Annotation\", fontsize = 15)\nplt.ylabel(\"Count\", fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:07:48.159062Z","iopub.execute_input":"2023-10-01T16:07:48.159416Z","iopub.status.idle":"2023-10-01T16:07:48.665548Z","shell.execute_reply.started":"2023-10-01T16:07:48.159385Z","shell.execute_reply":"2023-10-01T16:07:48.664861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Annotation distribution per video_id\n\nvideo_1 = (records_with_annotations[records_with_annotations[\"video_id\"] == 0][\"annotations\"]).count()\nvideo_2 = (records_with_annotations[records_with_annotations[\"video_id\"] == 1][\"annotations\"]).count()\nvideo_3 = (records_with_annotations[records_with_annotations[\"video_id\"] == 2][\"annotations\"]).count()\n\nax = sns.barplot(x=['Video id: 0', 'Video id: 1', 'Video id: 2'], y=[video_1, video_2, video_3])\nax.set_ylabel('Count')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:18.462668Z","iopub.execute_input":"2023-10-01T16:03:18.463039Z","iopub.status.idle":"2023-10-01T16:03:18.663688Z","shell.execute_reply.started":"2023-10-01T16:03:18.463006Z","shell.execute_reply":"2023-10-01T16:03:18.662204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Video with ID 2 has the least amount of annotations record.","metadata":{}},{"cell_type":"markdown","source":"## Detecting object with the help of a bounding box from a random image file","metadata":{}},{"cell_type":"markdown","source":"Each record in the annotation represents a bounding box. We can see from above exploration that one annotation list can have multiple records. So, this correspond to multiple bounding boxes.\nIn order to draw bounding box we must transform the annotations to list. annotations is in a string format. For bounding box the indices must be integers.","metadata":{}},{"cell_type":"code","source":"#Show image and annotations if applicable\ndef show_image(path, annot, axs=None):\n    '''Shows an image and marks any COTS annotated within the frame.\n    path: full path to the .jpg image\n    annot: string of the annotation for the coordinates of COTS'''\n    \n    # This is in case we plot only 1 image\n    if axs==None:\n        fig, axs = plt.subplots(figsize=(23, 8))\n    \n    img = plt.imread(path)\n    axs.imshow(img)\n\n    if annot:\n        for a in eval(annot):\n            rect = patches.Rectangle((a[\"x\"], a[\"y\"]), a[\"width\"], a[\"height\"], \n                                     linewidth=3, edgecolor=\"#FF6103\", facecolor='none')\n            axs.add_patch(rect)\n\n    axs.axis(\"off\")\n ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:18.668221Z","iopub.execute_input":"2023-10-01T16:03:18.668899Z","iopub.status.idle":"2023-10-01T16:03:18.675234Z","shell.execute_reply.started":"2023-10-01T16:03:18.668871Z","shell.execute_reply":"2023-10-01T16:03:18.674292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show only 1 image as example\npath = list(train[train[\"no_annotations\"]==0][\"image_path\"])[0]\nannot = list(train[train[\"no_annotations\"]==0][\"annotations\"])[0]\n\n\nprint(\"Path:\",path)\nprint(\"Annotation:\", annot)\nprint(\"Frame:\")\nshow_image(path, annot, axs=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:18.676643Z","iopub.execute_input":"2023-10-01T16:03:18.677044Z","iopub.status.idle":"2023-10-01T16:03:19.454291Z","shell.execute_reply.started":"2023-10-01T16:03:18.67702Z","shell.execute_reply":"2023-10-01T16:03:19.453405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show only 1 image as example\npath = list(train[train[\"no_annotations\"]==18][\"image_path\"])[0]\nannot = list(train[train[\"no_annotations\"]==18][\"annotations\"])[0]\n\n\nprint(\"Path:\",path)\nprint(\"Annotation:\", annot)\nprint(\"Frame:\")\nshow_image(path, annot, axs=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:19.455411Z","iopub.execute_input":"2023-10-01T16:03:19.455702Z","iopub.status.idle":"2023-10-01T16:03:20.225416Z","shell.execute_reply.started":"2023-10-01T16:03:19.455679Z","shell.execute_reply":"2023-10-01T16:03:20.224731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_multiple_images(seq_id, frame_no):\n    '''Shows multiple images within a sequence.\n    seq_id: a number corresponding with the sequence unique ID\n    frame_no: a list containing the first and last frame to plot'''\n    \n    # Select image paths & their annotations\n    paths = list(train[(train[\"sequence\"]==seq_id) & \n                 (train[\"sequence_frame\"]>=frame_no[0]) & \n                 (train[\"sequence_frame\"]<=frame_no[1])][\"image_path\"])\n    annotations = list(train[(train[\"sequence\"]==seq_id) & \n                 (train[\"sequence_frame\"]>=frame_no[0]) & \n                 (train[\"sequence_frame\"]<=frame_no[1])][\"annotations\"])\n\n    # Plot\n    fig, axs = plt.subplots(2, 3, figsize=(23, 10))\n    axs = axs.flatten()\n    fig.suptitle(f\"Showing consecutive frames for Sequence ID: {seq_id}\", fontsize = 20)\n\n    for k, (path, annot) in enumerate(zip(paths, annotations)):\n        axs[k].set_title(f\"Frame No: {frame_no[0]+k}\", fontsize = 12)\n        show_image(path, annot, axs[k])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:20.226574Z","iopub.execute_input":"2023-10-01T16:03:20.227324Z","iopub.status.idle":"2023-10-01T16:03:20.233847Z","shell.execute_reply.started":"2023-10-01T16:03:20.227298Z","shell.execute_reply":"2023-10-01T16:03:20.233079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example\nseq_id = 44160\nframe_no = [51, 56]\n\nshow_multiple_images(seq_id, frame_no)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:20.235036Z","iopub.execute_input":"2023-10-01T16:03:20.235529Z","iopub.status.idle":"2023-10-01T16:03:22.850986Z","shell.execute_reply.started":"2023-10-01T16:03:20.235504Z","shell.execute_reply":"2023-10-01T16:03:22.849572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example\nseq_id = 59337\nframe_no = [38, 43]\n\nshow_multiple_images(seq_id, frame_no)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:22.852475Z","iopub.execute_input":"2023-10-01T16:03:22.85293Z","iopub.status.idle":"2023-10-01T16:03:25.349485Z","shell.execute_reply.started":"2023-10-01T16:03:22.852904Z","shell.execute_reply":"2023-10-01T16:03:25.34402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compare images with the same number of annotations\ndef plot_comparison(no_annot, state=24):\n    \n    # Select image paths & their annotations\n    paths_compare = list(train[train[\"no_annotations\"]==no_annot]\\\n                         .sample(n=9, random_state=state)[\"image_path\"])\n    annotations_compare = list(train[train[\"no_annotations\"]==no_annot]\\\n                               .sample(n=9, random_state=state)[\"annotations\"])\n\n    # Plot\n    fig, axs = plt.subplots(3, 3, figsize=(23, 13))\n    axs = axs.flatten()\n    fig.suptitle(f\"{no_annot} annotations\", fontsize = 20)\n\n    for k, (path, annot) in enumerate(zip(paths_compare, annotations_compare)):\n        video_id = path.split(\"/\")[4]\n        frame_id = path.split(\"/\")[-1].split(\".\")[0]\n        \n        axs[k].set_title(f\"{video_id} | Frame {frame_id}\",\n                         fontsize = 12)\n        show_image(path, annot, axs[k])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:25.351294Z","iopub.execute_input":"2023-10-01T16:03:25.351815Z","iopub.status.idle":"2023-10-01T16:03:25.366164Z","shell.execute_reply.started":"2023-10-01T16:03:25.351737Z","shell.execute_reply":"2023-10-01T16:03:25.365205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# No annotations example\nno_annot = 0\nplot_comparison(no_annot, state=24)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:25.367738Z","iopub.execute_input":"2023-10-01T16:03:25.368256Z","iopub.status.idle":"2023-10-01T16:03:28.617825Z","shell.execute_reply.started":"2023-10-01T16:03:25.368222Z","shell.execute_reply":"2023-10-01T16:03:28.616681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#10 annotations example\nno_annot = 10\nplot_comparison(no_annot, state=24)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:28.619212Z","iopub.execute_input":"2023-10-01T16:03:28.619565Z","iopub.status.idle":"2023-10-01T16:03:32.473766Z","shell.execute_reply.started":"2023-10-01T16:03:28.619538Z","shell.execute_reply":"2023-10-01T16:03:32.472589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#formatting annotations\ndef format_annotations(x):\n    '''Changes annotations from format {x, y, width, height} to {x1, y1, x2, y2}.\n    x: a string of the initial format.'''\n    \n    annotations = eval(x)\n    new_annotations = []\n\n    if annotations:\n        for annot in annotations:\n            new_annotations.append([annot[\"x\"],\n                                    annot[\"y\"],\n                                    annot[\"x\"]+annot[\"width\"],\n                                    annot[\"y\"]+annot[\"height\"]\n                                   ])\n    \n    if new_annotations: return str(new_annotations)\n    else: return \"[]\"","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:32.47532Z","iopub.execute_input":"2023-10-01T16:03:32.475748Z","iopub.status.idle":"2023-10-01T16:03:32.482129Z","shell.execute_reply.started":"2023-10-01T16:03:32.475714Z","shell.execute_reply":"2023-10-01T16:03:32.481195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new column with the new formated annotations\ntrain[\"f_annotations\"] = train[\"annotations\"].apply(lambda x: format_annotations(x))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:32.483513Z","iopub.execute_input":"2023-10-01T16:03:32.484045Z","iopub.status.idle":"2023-10-01T16:03:32.948089Z","shell.execute_reply.started":"2023-10-01T16:03:32.484013Z","shell.execute_reply":"2023-10-01T16:03:32.947371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We will be using Yolov8 model, so we need the right format for annotations (labels):","metadata":{}},{"cell_type":"code","source":"def format_yolo_annotations(x):\n    '''Changes annotations from format {x, y, width, height} to {x1, y1, x2, y2}.\n    x: a string of the initial format.'''\n    \n    annotations = eval(x)\n    new_annotations = ''\n    img_h=720\n    img_w=1280\n\n    if annotations:\n        for annot in annotations:\n            current_category = 0\n            x = annot[\"x\"]\n            y = annot[\"y\"]\n            w = annot[\"width\"]\n            h = annot[\"height\"]\n            \n            # Finding midpoints\n            x_centre = (x + (x+w))/2\n            y_centre = (y + (y+h))/2\n\n            # Normalization\n            x_centre = x_centre / img_w\n            y_centre = y_centre / img_h\n            w = w / img_w\n            h = h / img_h\n\n            # Limiting upto fix number of decimal places\n            x_centre = format(x_centre, '.6f')\n            y_centre = format(y_centre, '.6f')\n            w = format(w, '.6f')\n            h = format(h, '.6f')\n        \n            new_annotations = new_annotations + (f\"{current_category} {x_centre} {y_centre} {w} {h}\\n\")\n\n    \n    if new_annotations: return new_annotations\n    else: return ''","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:32.949237Z","iopub.execute_input":"2023-10-01T16:03:32.949639Z","iopub.status.idle":"2023-10-01T16:03:32.95718Z","shell.execute_reply.started":"2023-10-01T16:03:32.949607Z","shell.execute_reply":"2023-10-01T16:03:32.956624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new column with the new formated annotations\ntrain[\"yolo_annot\"] = train[\"annotations\"].apply(lambda x: format_yolo_annotations(x))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:32.958174Z","iopub.execute_input":"2023-10-01T16:03:32.958618Z","iopub.status.idle":"2023-10-01T16:03:33.278463Z","shell.execute_reply.started":"2023-10-01T16:03:32.958593Z","shell.execute_reply":"2023-10-01T16:03:33.277712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Yolov8 model","metadata":{}},{"cell_type":"code","source":"train.tail()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:33.279587Z","iopub.execute_input":"2023-10-01T16:03:33.279844Z","iopub.status.idle":"2023-10-01T16:03:33.291882Z","shell.execute_reply.started":"2023-10-01T16:03:33.279823Z","shell.execute_reply":"2023-10-01T16:03:33.29094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create images directory for yolov8\nnewpath = '/kaggle/working/images/train/'\nif not os.path.exists(newpath):\n    os.makedirs(newpath)\n    \n#select img with annotations for .jpg\nimg_annot_jpg = []\nfor i,data in train.iterrows() :\n    if not data[\"annotations\"] == \"[]\":\n        img_annot_jpg.append(data[\"image_path\"])\n\nprint(len(img_annot_jpg)) #must be the same as before","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:33.292896Z","iopub.execute_input":"2023-10-01T16:03:33.293885Z","iopub.status.idle":"2023-10-01T16:03:34.220874Z","shell.execute_reply.started":"2023-10-01T16:03:33.29385Z","shell.execute_reply":"2023-10-01T16:03:34.21991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#copy images to right directory for yolov8\nimport shutil\ndir = '/kaggle/input/tensorflow-great-barrier-reef/train_images/'\ndest = '/kaggle/working/images/train/'\n\ncount=0\n\nfor file in os.listdir(dir):\n        folder = dir + file\n        for img in os.listdir(folder):\n            img_path = os.path.join(folder,img)\n            if img_path in img_annot_jpg:\n                count=count+1\n                shutil.copy(img_path, dest)\nprint(count) #must be the same as before","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:03:34.222093Z","iopub.execute_input":"2023-10-01T16:03:34.222389Z","iopub.status.idle":"2023-10-01T16:04:52.764574Z","shell.execute_reply.started":"2023-10-01T16:03:34.222365Z","shell.execute_reply":"2023-10-01T16:04:52.762635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create labels directory for yolov8\nnewpath = '/kaggle/working/labels/train/'\nif not os.path.exists(newpath):\n    os.makedirs(newpath)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:04:52.766965Z","iopub.execute_input":"2023-10-01T16:04:52.76749Z","iopub.status.idle":"2023-10-01T16:04:52.774669Z","shell.execute_reply.started":"2023-10-01T16:04:52.767454Z","shell.execute_reply":"2023-10-01T16:04:52.773939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#create labels directory for yolov8\ndest_labels = '/kaggle/working/labels/train/'\nif not os.path.exists(dest_labels):\n    os.makedirs(dest_labels)\n\ncount=0\n#select records with annotations for .txt and copy them in the right directory\nfor i,data in train.iterrows() :\n    if not data[\"annotations\"] == \"[]\":\n        count=count+1\n        file =  str(data[\"video_frame\"]) + \".txt\"\n        f = open(os.path.join(dest_labels,file),\"w\")\n        f.write(data[\"yolo_annot\"])\n        f.close()\n        \nprint(count) #must be the same as before","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:04:52.775958Z","iopub.execute_input":"2023-10-01T16:04:52.776361Z","iopub.status.idle":"2023-10-01T16:04:54.292545Z","shell.execute_reply.started":"2023-10-01T16:04:52.776339Z","shell.execute_reply":"2023-10-01T16:04:54.291508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check specific image for annotations/labels\nnum= 100 #put the choosen number to be checked\npath_l = '/kaggle/working/labels/train/'\npath_i = '/kaggle/working/images/train/'\nannot =  list(train[train[\"video_frame\"]==num][\"annotations\"])[0]\n\n\nlabel = str(num)+\".txt\"\nimage = str(num)+\".jpg\"\nprint (\"Image real path: \" + train[\"image_path\"][num])\nprint (\"Image yolo path: \" + os.path.join(path_i,image))\nprint(\"Annotations: \" + train[\"annotations\"][num])\nprint(\"\\n\")\nprint(\"Label yolo path: \" + os.path.join(path_l,label))\nf = open(os.path.join(path_l, label), 'r')\nprint(\"Annotations yolo format: \" +f.read())\nf.close()\nshow_image(os.path.join(path_i,image), annot, axs=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:04:54.29414Z","iopub.execute_input":"2023-10-01T16:04:54.294538Z","iopub.status.idle":"2023-10-01T16:04:55.061345Z","shell.execute_reply.started":"2023-10-01T16:04:54.294506Z","shell.execute_reply":"2023-10-01T16:04:55.060187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show only 1 image as example\npath = '/kaggle/working/images/train/9470.jpg'\nannot =  list(train[train[\"video_frame\"]==9470][\"annotations\"])[0]\n\n\nprint(\"Path:\",path)\nprint(\"Annotation:\", annot)\nprint(\"Frame:\")\nshow_image(path, annot, axs=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T13:32:27.154986Z","iopub.execute_input":"2023-10-03T13:32:27.155328Z","iopub.status.idle":"2023-10-03T13:32:27.550348Z","shell.execute_reply.started":"2023-10-03T13:32:27.155283Z","shell.execute_reply":"2023-10-03T13:32:27.548734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training:","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:04:55.807223Z","iopub.execute_input":"2023-10-01T16:04:55.807723Z","iopub.status.idle":"2023-10-01T16:05:17.814553Z","shell.execute_reply.started":"2023-10-01T16:04:55.807678Z","shell.execute_reply":"2023-10-01T16:05:17.813835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\n\n\n#Load model\nmodel = YOLO(\"yolov8n.yaml\") #build a new model from scratch\n\n#Use the model\nresults = model.train(data = \"/kaggle/input/data-settings/config.yml\", epochs=100) #train the model","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:05:17.81561Z","iopub.execute_input":"2023-10-01T16:05:17.817226Z","iopub.status.idle":"2023-10-01T16:05:54.855259Z","shell.execute_reply.started":"2023-10-01T16:05:17.817199Z","shell.execute_reply":"2023-10-01T16:05:54.851344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show Results","metadata":{}},{"cell_type":"code","source":"for file in os.listdir('/kaggle/working/runs/detect/train/'):\n    print(file)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:05:54.856602Z","iopub.status.idle":"2023-10-01T16:05:54.85767Z","shell.execute_reply.started":"2023-10-01T16:05:54.857376Z","shell.execute_reply":"2023-10-01T16:05:54.8574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\nres","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:05:54.860116Z","iopub.status.idle":"2023-10-01T16:05:54.861596Z","shell.execute_reply.started":"2023-10-01T16:05:54.861269Z","shell.execute_reply":"2023-10-01T16:05:54.861303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npath = '/kaggle/working/runs/detect/train/'\ndef show_res(file):\n    path = '/kaggle/working/runs/detect/train/'\n    fig, axs = plt.subplots(figsize=(23, 8))\n    file_path = os.path.join(path,file)\n    img = plt.imread(file_path)\n    fig.tight_layout()\n\n    axs.set_title(file, fontsize=20)\n    axs.imshow(img)\n\n\nfor file in os.listdir(path):\n    if file.endswith(('.png', '.jpg', '.jpeg')):\n        show_res(file)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:05:54.863831Z","iopub.status.idle":"2023-10-01T16:05:54.865063Z","shell.execute_reply.started":"2023-10-01T16:05:54.864757Z","shell.execute_reply":"2023-10-01T16:05:54.864784Z"},"trusted":true},"execution_count":null,"outputs":[]}]}